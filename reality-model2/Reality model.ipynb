{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essay\n",
    "The main idea we develop is that an agent starts with a set of sensors and a set of actuators. During its life, it learns how they are correlated. Then, the agents uses that map backwards to know what actions give them pleasure/pain. \n",
    "\n",
    "Interesting thoughts\n",
    "* Problem: if the agents needs to consider all the possible actions that modify our pleasure/pain, then it will have a combinatorical explosion. So, some heuristic is needed. One solution could be to at each timestep, limit the possible nodes we consider. \n",
    "* Problem: how do you decide what neurons connect together? Is it enough with neurons that fire together, wire together? What about two neurons that both are not firing? Should we connect them also?\n",
    "* The best state often isn't that dependent on the next action, but depends more on past or external events\n",
    "* Difference between intution and consciousness: how much we need to abstract to make a connection between sensors and actuators (ie, how many abstract nodes we need to pass through).\n",
    "\n",
    "# Logs\n",
    "First meeting\n",
    "0) Start with a model only with the available actions and sensors. We could have been added a \"genetic points\" concept. But it should appear naturally. \n",
    " \n",
    "1) Model reality, evolving abstractions and connections through evolution.\n",
    "\n",
    "How?\n",
    "* Have 10 - 100 agents\n",
    "\n",
    "Reasons:\n",
    "* Some events happen very rarely. During our life, we can't learn that dying is bad. \n",
    "* If there is a very strong correlation between two concepts, we don't want to lose it every generation.\n",
    "\n",
    "2) Model reality. \n",
    "How? \n",
    "* Concepts that fire together, wire together.\n",
    "* Allocating randomly empty concepts, connecting them to some sensor/actuator\n",
    "* GAN\n",
    "\n",
    "Reasons:\n",
    "* To avoid local optima\n",
    "* To have the possibility of changing env\n",
    "\n",
    "Conceptual map)\n",
    "Each connection has three numbers:\n",
    "* affectability: e.g., \n",
    "* percentage: e.g., when I press this button, I receive one cookie half of the time and a beef the other half of the time => the connection between \"button pressed\" and \"cookies\" has 50%.\n",
    "* certainity: e.g., when I press this button, I receive one cookie \n",
    "e.g., when I press a button, I receive two cookies half of the time => the connection between \"button pressed\" and \"cookies\" is affectability: two; percentage: 50%; certainty: not much{1}, for I pressed the button only once.\n",
    "\n",
    "It's both a way to featurize an state and a model of reality.\n",
    "It should be goal-driven\n",
    "\n",
    "Reasons:\n",
    "* The uncertainty indiciates the agent whether it can be confident in its policy or it should see what happens in the real world.\n",
    "\n",
    "Juntada 4\n",
    "¿Cómo modelar la realidad?\n",
    "Ponemos de inputs las entradas (posición/objetivo1) en un tiempo t y las acciones (movimiento/velocidad) que el agente puede tomar. Ponemos de outputs las entradas (posición/objetivo) en t+1.\n",
    "\n",
    "Funciona como una red neuronal, con abstracciones en el medio. Usamos una activation function y pesos con cualquier número real2 como valor.\n",
    "\n",
    "¿Cómo a partir de un modelo de la realidad podemos tomar acciones eficientes?\n",
    "Con un objetivo fijo, podemos recorrer la red neuronal de derecha a izquierda para encontrar que acciones maximizan/minimizan nuestro objetivo. \n",
    "\n",
    "Ahora, ¿qué pasa si lo que influye positivamente a nuestro objetivo en t es nuestra posición en t-1? No podemos cambiar la posición en t, pero podemos averiguar que cambia la posición. Si descubrimos que un actuador en t cambia nuestra posición en t+1, entonces podemos saber que activar un actuador en t influye positivamente a nuestro objetivo en t+2.\n",
    "\n",
    "Supongamos que recorremos de derecha a izquierda la red neuronal. Cómo hacemos por que camino seguir? Si el objetivo se conecta con mil neuronas y esas neuronas con otras mil, estamos en problemas. Una opción es elegir la conexión con el mayor peso. Pero me parece que para cumplir ciertos objetivos, necesitamos tomar varias acciones. Debe haber un punto intermedio entre la fuerza bruta de recorrer todas las neuronas y de recorrer solo una conexión a la vez. Hay que seguir pensando por acá: cómo decidimos recorrer la red neuronal para que nos de información sobre qué acciones son las óptimas? También habría que ver cómo hacer para ver más a futuro: cómo hacemos para saber como lo que hago en un tiempo t influye en t+100? Otra pregunta es cómo podemos tener en cuenta el estado actual (los valores de las entradas) para tomar la decisión de qué acción tomar.\n",
    "\n",
    "Otra cosa que se puede hacer es reducir el modelo de la realidad a un subconjunto de las acciones que nos interesan. Por ejemplo, dado un estado sabemos el valor de todas las entradas y podemos predecir la activación de todas las neuronas que no dependen de nuestras acciones. Esto nos permite recorrer la red neuronal de derecha a izquierda más fácilmente.\n",
    "\n",
    "Objetivos\n",
    "Un objetivo lo puedo dividir en una serie de subobjetivos que los tengo que hacer sincrónicamente3. A su vez, puedo dividir cada subobjetivo en subsubobjetivos. \n",
    "Hay objetivos que sabemos el camino completo a cumplirlos. Por ejemplo, si quiero tomar agua, sé que tengo que ir a la cocina, abrir la heladera, y agarrar una botella. Pero hay veces que sé cual es mi objetivo final pero no sé cómo llegar ahí. Por ejemplo, digamos que quiero ir a la luna. Cómo hago para saber que me va a llevar a la luna? Sé que googlear me va a dar un poco de información y voy construyendo a partir de ahí.\n",
    "\n",
    "Otras preguntas\n",
    "Supongamos que usamos una red neuronal común y corriente con backpropagation para resolver un problema. También supongamos que no le ponemos un modelo de la realidad ni nada de lo que hablamos acá. ¿La red neuronal desarrollará internamente un modelo de la realidad? Es decir, en las neuronas del medio, ¿se podrá encontrar un valor que se asemeje a una predicción del mundo y que la red neuronal la use para tomar sus decisiones?\n",
    "\n",
    "¿Cómo se traspasa conocimiento de una generación a otra?\n",
    "\n",
    "1\n",
    "How does a neuron decide which neurons to connect to?\n",
    "If two neurons are connected, we know that the connection is strengthen if it's useful and weakened if not. \n",
    "\n",
    "However, we don't know how two neurons get connected in the first place. One idea is that it's a stochastic process. Two random neurons get connected and if the connection is useless, it's discarded.\n",
    "\n",
    "Let's say we play a tone and some specific time later we give food to a dog. What's the minimum time for the dog needs to differentiate between two concepts (similar to plank's time, but for the brain.) Put in other words, the question is: how much time is needed to differentiate two events. Does this time change if the inputs are separated (such as tact and mouth.)\n",
    "\n",
    "If a concept predicts a severe concept (such as being poisoned), with one case is enough to make a connection.\n",
    "\n",
    "2\n",
    "If we can’t do now the model section, we can implement the RL + Evolution sections and then think about the model. Let’s do that. However, let’s first understand what I want in the model.\n",
    "\n",
    "Does this model differ from the RL MDP model?\n",
    "It’s atomized; that is, it’s separated on parts.\n",
    "\n",
    "3\n",
    "Let’s first implement one RL algorithm from scratch.\n",
    "\n",
    "What do we need?\n",
    "\n",
    "Receive S\n",
    "Get A from policy\n",
    "Take A and receive R, S’\n",
    "Save S, A, R, S’\n",
    "= alpha * "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
